% !TEX root = recommending-interesting-writing.tex
\section{Background}
\input{table/background}

We highlight two themes in research on recommendation models. We describe
recommendation models that incorporate side information and models that optimize
proxies of ranking metrics, and summarize this related work
in~\Cref{tab:background}.

\paragraph{Recommendation with side information} Side information is included in
recommendation models in several ways; we focus on deep learning and matrix
factorization approaches. Item side information can be modeled with deep
representations
\cite{zhang2017deep,bansal2016ask-the-gru:,lian2018towards,dong2017a-hybrid,chen2017joint,liang2018trsdl:,zuo2016tag-aware,xu2017tag-aware}
or can be included in content-based matrix factorization models as an additional
matrix
\cite{shi2014collaborative,gopalan2014content-based,wang2011collaborative,zhen2009tagicofi:,loepp2019interactive,bogers2018tag-based}.
Some deep learning based approaches scale to large datasets, but may not have
loss functions tied to evaluation metrics, or require data besides user-item
interactions. Content-based matrix factorization methods require learning
parameters for every item, and do not scale to data with large numbers of items.

\paragraph{Learning to rank} Recommendation models can be trained on loss
functions that approximate ranking-based evaluation metrics
\cite{yu2018walkranker:,liang2018top-n-rank:,rendle2009bpr:,song2018neural}, and
these models may include side information
\cite{shi2012tfmap:,yuan2016optimizing,ying2016collaborative,cao2017embedding,okura2017embedding-based}.
Such approaches may require data in addition to the user-item matrix, per-item
parameters, or use models where the output depends on the ordering of item
attributes.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "set_recommendation"
%%% End:

% as they are relevant to
% modeling items with attributes

% \paragraph{Deep representations of side information}
% Deep learning-based recommendation models incorporate side information in
% multiple ways \cite{zhang2017deep}. For example, items that have words as
% attributes can be represented using recurrent neural
% networks~\cite{bansal2016ask-the-gru:}. \citet{lian2018towards} use an attention
% mechanism to weight recommendations according to available item and user side
% information but not attributes, and \citet{dong2017a-hybrid} use denoising
% autoencoders to model side information in a deep recommendation model, but
% requires fitting parameters for every item. An example of a more efficient
% approach is the method in \citet{chen2017joint}, where embeddings are jointly
% learned for users, items, and item text for recommendation, but this method
% focuses on unsupervised pre-training of text representations. There are several
% examples of `tag-aware' or `tag-based' deep recommendation
% models~\cite{liang2018trsdl:,zuo2016tag-aware}, such as
% \citet{xu2017tag-awarey}, which focuses on data where users and items have
% different attributes and use autoencoders to learn user, item, and attribute
% representations. They use a cosine similarity-based objective function which is
% not tied to a metric used to evaluate recommendation performance.
%, but this method requires
%collecting information about which items users decided not to consume.

% \paragraph{Matrix factorization with side information}
% \citet{shi2014collaborative} survey several matrix factorization methods that
% incorporate side information. \citet{gopalan2014content-based} develop a
% Bayesian matrix factorization model for recommending items based on side
% information in the form of words in documents. \citet{wang2011collaborative}
% develop a regression model that uses a topic model to incorporate side
% information into recommendations. There are also several `tag-based' or
% `tag-aware' content-based matrix factorization
% models~\cite{zhen2009tagicofi:,loepp2019interactive,bogers2018tag-based}. Such
% content-based matrix factorization methods maximize the conditional
% log-likelihood of the data (or a bound on the log-likelihood); optimizing these
% objective functions does not optimize an evaluation metric. Furthermore, all of
% these methods are not scalable to large numbers of items as they require
% learning unique parameters for every item. Specifically, such content-based
% matrix factorization methods require learning a matrix that has a row for every
% item. For items with attributes, it is often infeasible to store this matrix in
% memory or exploit efficient coordinate ascent optimization schemes that require
% processing this entire matrix.

% \subsection{Recommendation via ranking}


% We describe recommendation models trained on
% such loss functions and extensions that include side information.

% \paragraph{Learning to rank}
% The literature on learning to rank includes models that optimize proxies of
% evaluation metrics, such as mean average precision, mean reciprocal rank, or
% discounted cumulative gain~\cite{yu2018walkranker:,liang2018top-n-rank:}. Forb
% example, Bayesian personalized ranking models optimize a pairwise ranking
% objective function \cite{rendle2009bpr:} that trains the model to rank items a
% user consumed higher than items a user did not consume. This objective is a
% heuristic motivated by an analogy to the receiver operating characteristic; a
% model trained on this objective does not provably maximize this metric.
% \citet{song2018neural} extend Bayesian personalized ranking using deep neural
% networks, but do not model side information.

% \paragraph{Learning to rank with side information}
% Models that optimize proxies of ranking metrics that use side information
% include \citet{shi2012tfmap:}, where a smoothed approximation of mean average
% precision is used as a loss function. \citet{yuan2016optimizing} use a proxy of
% a ranking loss to fit a polynomial that models predictions of item consumption
% using item and side information features. \citet{ying2016collaborative} uses
% denoising autoencoders to represent item information in a model trained with a
% pairwise ranking loss. \citet{cao2017embedding} use a ranking loss to jointly
% learn embeddings of items and attributes; they focus on the case where users
% interact directly with both attributes and items with said attributes. All of
% these models require learning unique parameters for every item, and do not scale
% to large numbers of items. An example of a scalable method that uses the
% Bayesian personalized ranking criterion is in \citet{okura2017embedding-based},
% but this approach requires data with timestamps and negative item feedback.


% \paragraph{Order-invariant models.} Deep learning architectures have been
% developed for set-valued input. Such architectures are invariant to permutations
% of set elements and can approximate any order-invariant function
% \cite{zaheer2017deep,ravanbakhsh2017equivariance}. This work
% addresses regression whereas we focus on recommendation, and develop a negative
% sampling technique.
% %
% \citet{kumar2018representation} extend the order-invariant architectures to the
% problem of a set-valued response; we focus on set-valued input for which data is
% more readily available.
% %
% \citet{benson2018sequences} study the problem of predicting sets in a sequential
% order. The task is to predict attributes of a new item given the number of
% attributes. These attributes are modeled as coming from the attributes of the
% items a user has recently consumed. In contrast, we do not focus on temporal
% data and do not focus on repeated consumption of whole or partial copies of of
% items' sets of attributes.

% \paragraph{Ranking models.} Bayesian personalized ranking models optimize a
% ranking criterion \cite{rendle2009bpr:} that trains the model to rank items a
% user consumed higher than items a user did not consume. The criterion is
% motivated by an analogy to the receiver operating characteristic, but they do
% not prove that optimizing the criterion is equivalent to optimizing this metric.
% In our work, we prove (in \Cref{prop:maximizing-recall}) that our approach
% directly optimizes recall.
% %
% The Bayesian personalized ranking criterion has been extended to recommending
% news articles \cite{okura2017embedding-based}, but this approach requires the
% collection of observed (but not consumed) items. Our method applies to data
% where this additional information is not required.

% % c.f. https://data.princeton.edu/wws509/notes/c6s3
% \paragraph{Discrete choice econometrics models.} Conditional logit models are
% used in economics to study purchasing decisions \cite{mcfadden1973conditional},
% and may include characteristics of items such as attributes.
% %
% \citet{ruiz2017shopper:} develop a sequential model for discrete choice of
% consumer behavior. They focus on predicting additional attributes for an item
% conditioned on its existing attributes, whereas our task concerns ranking items
% given their attributes.
% %
% \citet{chiong2019random} use random projections to reduce the dimensionality of
% the choice set in a discrete choice model (the number of items). However, it is
% unclear whether their model scales: they study a dataset with a choice set of
% size $3$k. The choice set in the diet data we study has tens of millions of
% items.
% %
% \citet{overgoor2018choosing} develop a discrete choice model for graph-based
% data where the task is predicting new edges. They use negative sampling as
% training data for missing links in the graph, but do not address the case where
% nodes have set-valued attributes (that is the case we focus on).

% \paragraph{Deep learning-based recommender systems.} \citet{zhang2017deep}
% reviews several deep learning models for recommending items to users. However,
% these models are recommend items without leveraging side information as we do in
% this work.
% %
% For example, \citet{nguyen2018npe:} develop a model for recommendation with
% negative sampling, where the context items are other items a user has consumed.
% (They not study the case where items are represented by sets of attributes.)
% %
% \citet{trofimov2018inferring} use a ranking loss with negative sampling for
% learning embeddings to predict attributes of an item conditional on existing
% attributes. Our task differs in that we aim to recommend items conditional on
% their full set of attributes.
% %
% \citet{chen2017joint} study the task of ranking text for users by incorporating
% different unsupervised representations of text. They do not address the task of
% recommending items that are represented by sets of attributes as we focus on
% here.

% \paragraph{Negative sampling in recommender systems.}
% \citet{chen2017on-sampling} analyze computational tradeoffs of different
% negative sampling strategies for recommender systems. Their work is
% complementary to ours, and could speed up the training of our model.
